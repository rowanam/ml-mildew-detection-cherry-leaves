{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aStgWSO0E0E"
      },
      "source": [
        "# Modeling and Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eLEkw5O0ECa"
      },
      "source": [
        "## Objectives\n",
        "\n",
        "* Answer business requirement 2:\n",
        "    - The client is interested in predicting if a cherry leaf is healthy or contains powdery mildew\n",
        "\n",
        "## Inputs\n",
        "\n",
        "* Split datasets:\n",
        "    - inputs/datasets/cherry-leaves/train\n",
        "    - inputs/datasets/cherry-leaves/validation\n",
        "    - inputs/datasets/cherry-leaves/test\n",
        "\n",
        "## Outputs\n",
        "\n",
        "* Plot of balance of target labels in each set\n",
        "* Target class names\n",
        "* Leaf health classification model\n",
        "* Model learning plots - loss and accuracy\n",
        "* Evaluation of test set performance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uWZXH9LwoQg"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqP-UeN-z3i2"
      },
      "source": [
        "## Change working directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOGIGS-uz3i2"
      },
      "source": [
        "Change working directory to project root directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wZfF_j-Bz3i4",
        "outputId": "66943449-1436-4c3d-85c7-b85f9f78349b"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vz3S-_kjz3jA",
        "outputId": "00b79ae4-75d0-4a96-d193-ac9ef9847ea2"
      },
      "outputs": [],
      "source": [
        "os.chdir(os.path.dirname(current_dir))\n",
        "\n",
        "# confirm new directory\n",
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Set up directories and variables"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Store file paths"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Input directories"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_dir = \"inputs/datasets/cherry-leaves\"\n",
        "\n",
        "train_dir = data_dir + \"/train\"\n",
        "val_dir = data_dir + \"/validation\"\n",
        "test_dir = data_dir + \"/test\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Create outputs directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Set version here\n",
        "version = \"v1\"\n",
        "\n",
        "file_path = f\"outputs/{version}\"\n",
        "\n",
        "if \"outputs\" in os.listdir(current_dir) and version in os.listdir(current_dir + \"/outputs\"):\n",
        "    print(\"This version tag has already been used. Create a new version.\")\n",
        "    pass\n",
        "else:\n",
        "    os.makedirs(name=file_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Store label names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "labels = os.listdir(train_dir)\n",
        "print(\"The image labels are:\", labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Import packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.image import imread\n",
        "import seaborn as sns\n",
        "\n",
        "sns.set_style(\"white\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Display balance of target labels in each set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# code adapted from Code Institute walkthrough projects\n",
        "# e.g. https://github.com/Code-Institute-Solutions/WalkthroughProject01\n",
        "def plot_target_balance_per_set(data_dir, save_image=False):\n",
        "    df_freq = pd.DataFrame([])\n",
        "    for folder in [\"train\", \"validation\", \"test\"]:\n",
        "        for label in labels:\n",
        "            df_freq = df_freq.append(\n",
        "                pd.Series(\n",
        "                    data={\n",
        "                        \"Set\": folder,\n",
        "                        \"Label\": label,\n",
        "                        \"Frequency\": int(\n",
        "                            len(os.listdir(data_dir + \"/\" + folder + \"/\" + label))\n",
        "                        ),\n",
        "                    }\n",
        "                ),\n",
        "                ignore_index=True,\n",
        "            )\n",
        "\n",
        "            print(\n",
        "                f\"* {folder} - {label}: {len(os.listdir(data_dir+'/'+ folder + '/' + label))} images\"\n",
        "            )\n",
        "\n",
        "    print(\"\\n\")\n",
        "    sns.set_style(\"white\")\n",
        "    plt.figure(figsize=(8, 5))\n",
        "    sns.barplot(data=df_freq, x=\"Set\", y=\"Frequency\", hue=\"Label\")\n",
        "\n",
        "    if save_image:\n",
        "        plt.savefig(\n",
        "            f\"{file_path}/labels_distribution.png\", bbox_inches=\"tight\", dpi=150\n",
        "        )\n",
        "\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_target_balance_per_set(data_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Save if image looks good"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_target_balance_per_set(data_dir, save_image=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZY3l0-AxO93d"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Images are loaded in batches to reduce working memory usage during model training.\n",
        "\n",
        "`label_mode` is set as `categorical` as this one-hot-encodes the target - needed for training the model with a final softmax activation layer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.utils import image_dataset_from_directory\n",
        "\n",
        "batch_size = 20\n",
        "\n",
        "train_set = image_dataset_from_directory(\n",
        "    train_dir,\n",
        "    label_mode=\"categorical\",  # encode labels as categorical vector, i.e. OHE\n",
        "    seed=123,\n",
        "    batch_size=batch_size,\n",
        ")\n",
        "\n",
        "train_set  # second shape tuple should be (None, 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "validation_set = image_dataset_from_directory(\n",
        "    train_dir,\n",
        "    label_mode=\"categorical\",\n",
        "    seed=123,\n",
        "    batch_size=batch_size,\n",
        ")\n",
        "\n",
        "validation_set  # second shape tuple should be (None, 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_set = image_dataset_from_directory(\n",
        "    train_dir,\n",
        "    label_mode=\"categorical\",\n",
        "    seed=123,\n",
        "    batch_size=batch_size,\n",
        ")\n",
        "\n",
        "test_set  # second shape tuple should be (None, 2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Save class names"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Save label class names so these can be displayed to the user after predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import joblib\n",
        "\n",
        "joblib.dump(value=train_set.class_names, filename=f\"{file_path}/class_names.pkl\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Define model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# import packages\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import (\n",
        "    Activation,\n",
        "    Dropout,\n",
        "    Flatten,\n",
        "    Dense,\n",
        "    Conv2D,\n",
        "    MaxPooling2D,\n",
        "    Rescaling\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Initially, we create a fairly standard convolutional neural network as a starting point.\n",
        "\n",
        "* Rescaling is done within the model (first layer) so that any image passed in real time will have this applied automatically\n",
        "* Three pairs of convolution/pooling layers are used with kernel sizes of 3 x 3 and pool sizes of 2 x 2, as this is a standard starting configuration (see e.g. Code Institue [Walkthrough Project 1](https://github.com/Code-Institute-Solutions/WalkthroughProject01))\n",
        "* A Flatten layer flattens the data into a format that the subsequent Dense layers can process more easily\n",
        "* One Dense layer is used, followed by a dropout layer to reduc the risk of model overfitting\n",
        "* The output layer uses a softmax activation function with 2 neurons since there are 2 label classes - because of this, the loss function used is `categorical_crossentropy` (see for example CI TensorFlow lesson)\n",
        "* The optimzer is `adam` and the performance metric evaluated is overall accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# shape of all images in dataset\n",
        "image_shape = (256, 256, 3)\n",
        "\n",
        "\n",
        "def create_model():\n",
        "    model = Sequential()\n",
        "\n",
        "    # rescale data\n",
        "    model.add(Rescaling(1.0 / 255))\n",
        "\n",
        "    # first pair\n",
        "    model.add(\n",
        "        Conv2D(\n",
        "            filters=32,\n",
        "            kernel_size=(3, 3),\n",
        "            input_shape=image_shape,\n",
        "            activation=\"relu\",\n",
        "        )\n",
        "    )\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    # second pair\n",
        "    model.add(\n",
        "        Conv2D(\n",
        "            filters=64,\n",
        "            kernel_size=(3, 3),\n",
        "            input_shape=image_shape,\n",
        "            activation=\"relu\",\n",
        "        )\n",
        "    )\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    # third pair\n",
        "    model.add(\n",
        "        Conv2D(\n",
        "            filters=64,\n",
        "            kernel_size=(3, 3),\n",
        "            input_shape=image_shape,\n",
        "            activation=\"relu\",\n",
        "        )\n",
        "    )\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    model.add(Flatten())\n",
        "\n",
        "    model.add(Dense(128, activation=\"relu\"))\n",
        "    model.add(Dropout(0.5))\n",
        "\n",
        "    model.add(Dense(2, activation=\"softmax\"))\n",
        "\n",
        "    model.compile(\n",
        "        loss=\"categorical_crossentropy\",\n",
        "        optimizer=\"adam\",\n",
        "        metrics=[\"accuracy\"],\n",
        "    )\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Train model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Define early stopping to avoid model overfitting. Stop model training when the validation set accuracy stops improving."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Initially tried `patience` of 10, then 5, which both led to model overfitting (drop in validation accuracy in last epoch(s))."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "early_stop = EarlyStopping(monitor=\"val_accuracy\", patience=3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Fit the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = create_model()\n",
        "\n",
        "model.fit(\n",
        "    train_set,\n",
        "    epochs=100,\n",
        "    validation_data=validation_set,\n",
        "    callbacks=[early_stop],\n",
        "    verbose=1,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Save the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.save('outputs/v1/leaf_health_clf_model.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Evaluate model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Plot model learning curve"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Plot loss and accuracy for training and validation sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_learning_curve(model, save_image=False):\n",
        "    losses = pd.DataFrame(model.history.history)\n",
        "\n",
        "    sns.set_style(\"whitegrid\")\n",
        "    losses[[\"loss\", \"val_loss\"]].plot(style=\".-\")\n",
        "    plt.title(\"Loss\")\n",
        "    if save_image:\n",
        "        plt.savefig(f\"{file_path}/model_training_losses.png\", bbox_inches=\"tight\", dpi=150)\n",
        "    plt.show()\n",
        "\n",
        "    print(\"\\n\")\n",
        "    losses[[\"accuracy\", \"val_accuracy\"]].plot(style=\".-\")\n",
        "    plt.title(\"Accuracy\")\n",
        "    if save_image:\n",
        "        plt.savefig(f\"{file_path}/model_training_accuracy.png\", bbox_inches=\"tight\", dpi=150)\n",
        "    plt.show()\n",
        "\n",
        "plot_learning_curve(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Discussion: both the train and validation sets have low loss and high accuracy. The lines have similar shapes and the validation set performance is not significantly different from that of the train set, suggesting that the model did non overfit."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Save if images look good"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_learning_curve(model, save_image=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Test model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Test model on test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "evaluation = model.evaluate(test_set)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Save test evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "joblib.dump(value=evaluation, filename=f\"outputs/v1/evaluation.pkl\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Check model size"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "GitHub limit: 100MB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "os.stat('outputs/v1/leaf_health_clf_model.h5').st_size"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Test prediction on live data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Choose a random image from the test dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing import image\n",
        "\n",
        "pointer = 66  # choose a random number to select an image\n",
        "label = labels[0]  # select class of leaf image\n",
        "\n",
        "test_image = image.load_img(\n",
        "    test_dir + \"/\" + label + \"/\" + os.listdir(test_dir + \"/\" + label)[pointer],\n",
        "    target_size=image_shape,  # resize to model training image size\n",
        "    color_mode=\"rgb\",\n",
        ")\n",
        "\n",
        "print(f\"Image shape: {test_image.size}\")\n",
        "test_image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Convert the image to an array and add a dimension of length 1 (the model expects a dimension indicating the number of images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_image = np.expand_dims(image.img_to_array(test_image), axis=0)\n",
        "test_image.shape  # should be (1, 256, 256, 3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Use the model to make a prediction and display the most likely label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class_names = train_set.class_names\n",
        "\n",
        "# predict on the data, returns an array of probabilities\n",
        "prediction_probs = model.predict(test_image)\n",
        "\n",
        "# get the index of the highest probability, use to select label from class_names\n",
        "prediction_class = class_names[np.argmax(prediction_probs, axis=1)[0]]\n",
        "prediction_class"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ltNetd085qHf"
      },
      "source": [
        "## Conlusions and next steps"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The trained model performed with 99% accuracy on the test data, which meets the business requirement (97% accuracy). Due to this, no further dataset manipulation (such as image augmentation) or model training steps were required. The model, plots and other outputs outlined at the begnning of the notebook have been saved, ready for use in the dashboard. An image was used to test whether a label prediction can be made on live data.\n",
        "\n",
        "The model currently has very high performance but is fairly large. If desired by the client, a potential next step might be to develop a smaller model that has comparable performance. An initial approach in this case would be to reduce the size of training images."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Data Practitioner Jupyter Notebook.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "interpreter": {
      "hash": "8b8334dab9339717f727a1deaf837b322d7a41c20d15cc86be99a8e69ceec8ce"
    },
    "kernelspec": {
      "display_name": "Python 3.8.12 64-bit ('3.8.12': pyenv)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    },
    "orig_nbformat": 2
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
